// =============================================
// GROWLOG - Migration v13 ‚Üí v14
// SOFT-DELETE SYSTEM: Prevent Data Loss on Entity Deletion
// =============================================

import 'package:growlog_app/database/migrations/migration.dart';
import 'package:growlog_app/utils/app_logger.dart';

/// Migration v14: Soft-Delete System with Data Protection
///
/// PROBLEMS FIXED:
/// 1. CASCADE DELETE causes data loss when deleting plants (logs, photos, harvests gone!)
/// 2. CASCADE DELETE causes data loss when deleting RDWC systems (all logs gone!)
/// 3. No warning to users before destructive deletion
/// 4. No way to recover accidentally deleted data
///
/// SOLUTIONS:
/// 1. Add archived flag to plant_logs, rdwc_logs, rooms
/// 2. Change CASCADE DELETE ‚Üí RESTRICT for critical relations
/// 3. Enable soft-delete pattern (archive instead of delete)
/// 4. Add indexes for efficient archived filtering
///
/// IMPACT:
/// - Prevents accidental data loss
/// - Enables data recovery through archives
/// - Maintains referential integrity
/// - Improves data audit trail
///
/// SAFETY:
/// - All data preserved during migration
/// - New archived columns default to 0 (not archived)
/// - RESTRICT constraints prevent orphaned records
/// - Automatic backup by MigrationManager
final Migration migrationV14 = Migration(
  version: 14,
  description: 'Soft-Delete System: Prevent data loss on deletion',
  up: (db) async {
    AppLogger.info(
      'Migration_v14',
      'üîÑ Starting Migration v14: Soft-Delete System',
    );

    // ===========================================
    // STEP 0: Pre-Migration Schema Validation
    // ===========================================
    AppLogger.info('Migration_v14', 'üîç Step 0/9: Validating schema');

    bool isAlreadyV14 = false;

    try {
      // Validate plant_logs schema (most complex migration)
      final plantLogsColumns = await db.rawQuery(
        'PRAGMA table_info(plant_logs)',
      );
      final columnNames = plantLogsColumns
          .map((col) => col['name'] as String)
          .toSet();

      // Check if database has v13 schema (old column names)
      final v13Columns = {'watering_ml', 'nutrient_ec', 'ph'};
      final hasV13Schema = v13Columns.every((col) => columnNames.contains(col));

      // Check if database has v14 schema (new column names)
      final v14Columns = {'water_amount', 'ph_in', 'ec_in'};
      final hasV14Schema = v14Columns.every((col) => columnNames.contains(col));

      // Also check photos table schema
      final photosColumnsCheck = await db.rawQuery(
        'PRAGMA table_info(photos)',
      );
      final photoColumnNamesCheck = photosColumnsCheck
          .map((col) => col['name'] as String)
          .toSet();
      final photosHasV14 = photoColumnNamesCheck.contains('image_path');
      final photosHasV13 = photoColumnNamesCheck.contains('file_path');

      // Consider it v14 if plant_logs have v14 schema (even if photos don't)
      // We'll handle photos separately in the early exit logic
      if (hasV14Schema) {
        AppLogger.warning(
          'Migration_v14',
          '‚ö†Ô∏è plant_logs already have v14 schema, checking for partial migration...',
        );
        if (!photosHasV14 && photosHasV13) {
          AppLogger.info(
            'Migration_v14',
            '  Photos still have v13 schema - will migrate in early exit',
          );
        }
        isAlreadyV14 = true;
      } else if (!hasV13Schema && !hasV14Schema) {
        final error =
            '‚ùå Schema validation failed!\n'
            'Database has neither v13 nor v14 schema.\n'
            'Found columns: ${columnNames.join(", ")}\n'
            'This indicates database corruption or version mismatch.';
        AppLogger.error('Migration_v14', error);
        throw Exception(error);
      } else {
        AppLogger.info(
          'Migration_v14',
          '  ‚úÖ v13 schema detected, proceeding with migration',
        );
      }

      // Validate other critical tables exist
      final tables = await db.rawQuery(
        "SELECT name FROM sqlite_master WHERE type='table' AND name IN ('plants', 'photos', 'harvests', 'rdwc_logs', 'rdwc_systems')",
      );

      if (tables.length < 5) {
        final foundTables = tables.map((t) => t['name']).join(', ');
        final error =
            '‚ùå Critical tables missing!\n'
            'Expected: plants, photos, harvests, rdwc_logs, rdwc_systems\n'
            'Found: $foundTables';
        AppLogger.error('Migration_v14', error);
        throw Exception(error);
      }

      AppLogger.info('Migration_v14', '  ‚úÖ Schema validation passed');
    } catch (e) {
      AppLogger.error(
        'Migration_v14',
        '‚ùå Pre-migration validation failed - aborting migration!',
        e,
      );
      rethrow; // Abort migration - will trigger database recovery
    }

    // If already v14, only ensure archived columns exist and exit
    if (isAlreadyV14) {
      AppLogger.info('Migration_v14', 'üìù Ensuring archived columns and photos schema exist');

      // Check and add archived columns if missing
      try {
        await db.execute(
          'ALTER TABLE plant_logs ADD COLUMN archived INTEGER DEFAULT 0',
        );
        AppLogger.info('Migration_v14', '  ‚úÖ Added archived to plant_logs');
      } catch (e) {
        // Column already exists, ignore
        AppLogger.debug(
          'Migration_v14',
          '  archived already exists in plant_logs',
        );
      }

      try {
        await db.execute(
          'ALTER TABLE rdwc_logs ADD COLUMN archived INTEGER DEFAULT 0',
        );
        AppLogger.info('Migration_v14', '  ‚úÖ Added archived to rdwc_logs');
      } catch (e) {
        AppLogger.debug(
          'Migration_v14',
          '  archived already exists in rdwc_logs',
        );
      }

      try {
        await db.execute(
          'ALTER TABLE rooms ADD COLUMN archived INTEGER DEFAULT 0',
        );
        AppLogger.info('Migration_v14', '  ‚úÖ Added archived to rooms');
      } catch (e) {
        AppLogger.debug('Migration_v14', '  archived already exists in rooms');
      }

      // Check if plant_logs need to be migrated from old schema
      final logsCheck = await db.rawQuery('PRAGMA table_info(plant_logs)');
      final logsColNames = logsCheck.map((col) => col['name'] as String).toSet();
      final hasWateringMl = logsColNames.contains('watering_ml');
      final hasWaterAmount = logsColNames.contains('water_amount');

      if (hasWateringMl && !hasWaterAmount) {
        AppLogger.info(
          'Migration_v14',
          '  ‚ö†Ô∏è plant_logs still have v13 schema, migrating now...',
        );

        // Migrate plant_logs v13 ‚Üí v14
        // ‚úÖ FIX: Add missing CHECK and DEFAULT constraints
        await db.execute('''
          CREATE TABLE plant_logs_new (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            plant_id INTEGER NOT NULL,
            day_number INTEGER NOT NULL,
            log_date TEXT NOT NULL DEFAULT (datetime('now')),
            logged_by TEXT,
            action_type TEXT NOT NULL CHECK(action_type IN ('WATER', 'FEED', 'NOTE', 'PHASE_CHANGE', 'TRANSPLANT', 'HARVEST', 'TRAINING', 'TRIM', 'OTHER')),
            phase TEXT CHECK(phase IN ('SEEDLING', 'VEG', 'BLOOM', 'HARVEST', 'ARCHIVED')),
            phase_day_number INTEGER,
            water_amount REAL,
            ph_in REAL,
            ph_out REAL,
            ec_in REAL,
            ec_out REAL,
            temperature REAL,
            humidity REAL,
            runoff INTEGER DEFAULT 0,
            cleanse INTEGER DEFAULT 0,
            container_size REAL,
            container_medium_amount REAL,
            container_drainage INTEGER DEFAULT 0,
            container_drainage_material TEXT,
            system_reservoir_size REAL,
            system_bucket_count INTEGER,
            system_bucket_size REAL,
            note TEXT,
            archived INTEGER DEFAULT 0,
            created_at TEXT DEFAULT (datetime('now')),
            FOREIGN KEY (plant_id) REFERENCES plants(id) ON DELETE RESTRICT
          )
        ''');

        await db.execute('''
          INSERT INTO plant_logs_new (
            id, plant_id, day_number, log_date, logged_by, action_type, phase, phase_day_number,
            water_amount, ph_in, ph_out, ec_in, ec_out, temperature, humidity,
            runoff, cleanse, container_size, container_medium_amount, container_drainage,
            container_drainage_material, system_reservoir_size, system_bucket_count,
            system_bucket_size, note, archived, created_at
          )
          SELECT
            id, plant_id, day_number, log_date,
            NULL as logged_by,
            action_type, phase, phase_day_number,
            watering_ml as water_amount,
            ph as ph_in,
            NULL as ph_out,
            nutrient_ec as ec_in,
            NULL as ec_out,
            temperature, humidity,
            0 as runoff,
            0 as cleanse,
            NULL as container_size,
            NULL as container_medium_amount,
            0 as container_drainage,
            NULL as container_drainage_material,
            NULL as system_reservoir_size,
            NULL as system_bucket_count,
            NULL as system_bucket_size,
            note,
            COALESCE(archived, 0) as archived,
            created_at
          FROM plant_logs
        ''');

        await db.execute('DROP TABLE plant_logs');
        await db.execute('ALTER TABLE plant_logs_new RENAME TO plant_logs');

        // Re-create indexes
        await db.execute('CREATE INDEX idx_logs_plant ON plant_logs(plant_id)');
        await db.execute('CREATE INDEX idx_logs_date ON plant_logs(log_date DESC)');
        await db.execute('CREATE INDEX idx_plant_logs_plant_archived ON plant_logs(plant_id, archived)');
        await db.execute('CREATE INDEX idx_plant_logs_archived_date ON plant_logs(archived, log_date DESC)');

        AppLogger.info('Migration_v14', '  ‚úÖ plant_logs migrated (v13 ‚Üí v14)');
      } else if (hasWaterAmount) {
        AppLogger.info('Migration_v14', '  ‚úÖ plant_logs already have v14 schema');
      }

      // Check if photos need to be migrated from old schema (file_path ‚Üí image_path)
      final photosCheck = await db.rawQuery('PRAGMA table_info(photos)');
      final hasFilePath = photosCheck.any((col) => col['name'] == 'file_path');
      final hasImagePath = photosCheck.any((col) => col['name'] == 'image_path');

      if (hasFilePath && !hasImagePath) {
        AppLogger.info(
          'Migration_v14',
          '  ‚ö†Ô∏è Photos still have old schema, migrating photos table...',
        );

        // Migrate photos table
        // ‚úÖ FIX: photos.log_id should be CASCADE (photos should be deleted with log)
        await db.execute('''
          CREATE TABLE photos_new (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            log_id INTEGER,
            image_path TEXT NOT NULL,
            description TEXT,
            taken_at TEXT DEFAULT (datetime('now')),
            created_at TEXT DEFAULT (datetime('now')),
            FOREIGN KEY (log_id) REFERENCES plant_logs(id) ON DELETE CASCADE
          )
        ''');

        await db.execute('''
          INSERT INTO photos_new (id, log_id, image_path, created_at)
          SELECT id, log_id, file_path, created_at
          FROM photos
        ''');

        await db.execute('DROP TABLE photos');
        await db.execute('ALTER TABLE photos_new RENAME TO photos');
        await db.execute('CREATE INDEX idx_photos_log ON photos(log_id)');

        AppLogger.info('Migration_v14', '  ‚úÖ Photos migrated (file_path ‚Üí image_path)');
      } else if (hasImagePath) {
        AppLogger.info('Migration_v14', '  ‚úÖ Photos already have v14 schema');
      }

      AppLogger.info(
        'Migration_v14',
        'üéâ Migration v14 complete (schema already up-to-date)',
      );
      return; // Exit early
    }

    // ===========================================
    // STEP 1: Add archived flags
    // ===========================================
    AppLogger.info('Migration_v14', 'üìù Step 1/9: Adding archived columns');

    await db.execute(
      'ALTER TABLE plant_logs ADD COLUMN archived INTEGER DEFAULT 0',
    );
    await db.execute(
      'ALTER TABLE rdwc_logs ADD COLUMN archived INTEGER DEFAULT 0',
    );
    await db.execute('ALTER TABLE rooms ADD COLUMN archived INTEGER DEFAULT 0');

    AppLogger.info('Migration_v14', '  ‚úÖ archived columns added to 3 tables');

    // ===========================================
    // STEP 2: Rebuild plant_logs with RESTRICT
    // ===========================================
    AppLogger.info(
      'Migration_v14',
      'üìù Step 2/9: Rebuilding plant_logs (CASCADE ‚Üí RESTRICT)',
    );

    // ‚úÖ CRITICAL FIX: Use correct v14 schema with all required columns and constraints
    await db.execute('''
      CREATE TABLE plant_logs_new (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        plant_id INTEGER NOT NULL,
        day_number INTEGER NOT NULL,
        log_date TEXT NOT NULL DEFAULT (datetime('now')),
        logged_by TEXT,
        action_type TEXT NOT NULL CHECK(action_type IN ('WATER', 'FEED', 'NOTE', 'PHASE_CHANGE', 'TRANSPLANT', 'HARVEST', 'TRAINING', 'TRIM', 'OTHER')),
        phase TEXT CHECK(phase IN ('SEEDLING', 'VEG', 'BLOOM', 'HARVEST', 'ARCHIVED')),
        phase_day_number INTEGER,
        water_amount REAL,
        ph_in REAL,
        ph_out REAL,
        ec_in REAL,
        ec_out REAL,
        temperature REAL,
        humidity REAL,
        runoff INTEGER DEFAULT 0,
        cleanse INTEGER DEFAULT 0,
        container_size REAL,
        container_medium_amount REAL,
        container_drainage INTEGER DEFAULT 0,
        container_drainage_material TEXT,
        system_reservoir_size REAL,
        system_bucket_count INTEGER,
        system_bucket_size REAL,
        note TEXT,
        archived INTEGER DEFAULT 0,
        created_at TEXT DEFAULT (datetime('now')),
        FOREIGN KEY (plant_id) REFERENCES plants(id) ON DELETE RESTRICT
      )
    ''');

    // ‚úÖ CRITICAL FIX: Map v13 columns to v14 schema
    // v13 had: id, plant_id, log_date, action_type, day_number, phase, phase_day_number,
    //          watering_ml, nutrient_ppm, nutrient_ec, ph, temperature, humidity,
    //          light_hours, note, training, defoliation, created_at
    // v14 has: All above PLUS logged_by, water_amount (renamed), ph_in/ph_out (split),
    //          ec_in/ec_out (split), runoff, cleanse, container_*, system_*, archived
    // Dropped: nutrient_ppm, nutrient_ec, light_hours, training, defoliation
    await db.execute('''
      INSERT INTO plant_logs_new (
        id, plant_id, day_number, log_date, logged_by, action_type, phase, phase_day_number,
        water_amount, ph_in, ph_out, ec_in, ec_out, temperature, humidity,
        runoff, cleanse, container_size, container_medium_amount, container_drainage,
        container_drainage_material, system_reservoir_size, system_bucket_count,
        system_bucket_size, note, archived, created_at
      )
      SELECT
        id, plant_id, day_number, log_date,
        NULL as logged_by,  -- NEW column
        action_type, phase, phase_day_number,
        watering_ml as water_amount,  -- RENAMED
        ph as ph_in,  -- SPLIT: old ph becomes ph_in
        NULL as ph_out,  -- SPLIT: ph_out is NULL for old data
        nutrient_ec as ec_in,  -- SPLIT: nutrient_ec becomes ec_in
        NULL as ec_out,  -- SPLIT: ec_out is NULL for old data
        temperature, humidity,
        0 as runoff,  -- NEW column with default
        0 as cleanse,  -- NEW column with default
        NULL as container_size,  -- NEW column
        NULL as container_medium_amount,  -- NEW column
        0 as container_drainage,  -- NEW column with default
        NULL as container_drainage_material,  -- NEW column
        NULL as system_reservoir_size,  -- NEW column
        NULL as system_bucket_count,  -- NEW column
        NULL as system_bucket_size,  -- NEW column
        note,
        archived,  -- Column already added in STEP 1
        created_at
      FROM plant_logs
    ''');

    await db.execute('DROP TABLE plant_logs');
    await db.execute('ALTER TABLE plant_logs_new RENAME TO plant_logs');

    AppLogger.info(
      'Migration_v14',
      '  ‚úÖ plant_logs: ON DELETE CASCADE ‚Üí RESTRICT',
    );

    // ===========================================
    // STEP 3: Rebuild photos with RESTRICT
    // ===========================================
    AppLogger.info(
      'Migration_v14',
      'üìù Step 3/9: Rebuilding photos (CASCADE ‚Üí RESTRICT)',
    );

    // Check current photos schema to determine correct migration path
    final photosSchemaCheck = await db.rawQuery('PRAGMA table_info(photos)');
    final photosColNames = photosSchemaCheck
        .map((col) => col['name'] as String)
        .toSet();
    final hasFilePath = photosColNames.contains('file_path');
    final hasImagePath = photosColNames.contains('image_path');

    if (hasImagePath) {
      // Photos already have v14 schema, just verify RESTRICT constraint
      AppLogger.info(
        'Migration_v14',
        '  ‚ö†Ô∏è Photos already have v14 schema (image_path), verifying constraints...',
      );

      // Rebuild anyway to ensure ON DELETE CASCADE is set (photos should be deleted with log)
      // ‚úÖ FIX: Changed RESTRICT ‚Üí CASCADE
      await db.execute('''
        CREATE TABLE photos_new (
          id INTEGER PRIMARY KEY AUTOINCREMENT,
          log_id INTEGER,
          image_path TEXT NOT NULL,
          description TEXT,
          taken_at TEXT DEFAULT (datetime('now')),
          created_at TEXT DEFAULT (datetime('now')),
          FOREIGN KEY (log_id) REFERENCES plant_logs(id) ON DELETE CASCADE
        )
      ''');

      await db.execute('''
        INSERT INTO photos_new
        SELECT * FROM photos
      ''');
      await db.execute('DROP TABLE photos');
      await db.execute('ALTER TABLE photos_new RENAME TO photos');

      AppLogger.info('Migration_v14', '  ‚úÖ photos: Verified ON DELETE RESTRICT');
    } else if (hasFilePath) {
      // Photos have old v13 schema, migrate file_path ‚Üí image_path
      AppLogger.info(
        'Migration_v14',
        '  üìù Migrating photos: file_path ‚Üí image_path',
      );

      // ‚úÖ FIX: photos.log_id should be CASCADE (photos should be deleted with log)
      await db.execute('''
        CREATE TABLE photos_new (
          id INTEGER PRIMARY KEY AUTOINCREMENT,
          log_id INTEGER,
          image_path TEXT NOT NULL,
          description TEXT,
          taken_at TEXT DEFAULT (datetime('now')),
          created_at TEXT DEFAULT (datetime('now')),
          FOREIGN KEY (log_id) REFERENCES plant_logs(id) ON DELETE CASCADE
        )
      ''');

      // ‚úÖ CRITICAL FIX: Map old schema (file_path) to new schema (image_path)
      // Old schema: id, log_id, file_path, created_at
      // New schema: id, log_id, image_path, description, taken_at, created_at
      await db.execute('''
        INSERT INTO photos_new (id, log_id, image_path, created_at)
        SELECT id, log_id, file_path, created_at
        FROM photos
      ''');
      await db.execute('DROP TABLE photos');
      await db.execute('ALTER TABLE photos_new RENAME TO photos');

      AppLogger.info('Migration_v14', '  ‚úÖ photos: file_path ‚Üí image_path, CASCADE ‚Üí RESTRICT');
    } else {
      AppLogger.warning(
        'Migration_v14',
        '  ‚ö†Ô∏è Photos have unexpected schema, skipping migration',
      );
    }

    // ===========================================
    // STEP 4: Rebuild harvests with RESTRICT
    // ===========================================
    AppLogger.info(
      'Migration_v14',
      'üìù Step 4/9: Rebuilding harvests (CASCADE ‚Üí RESTRICT)',
    );

    await db.execute('''
      CREATE TABLE harvests_new (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        plant_id INTEGER NOT NULL,
        harvest_date TEXT NOT NULL,
        wet_weight REAL,
        dry_weight REAL,
        curing_start_date TEXT,
        curing_end_date TEXT,
        curing_method TEXT,
        curing_notes TEXT,
        thc_percentage REAL,
        cbd_percentage REAL,
        terpene_profile TEXT,
        rating INTEGER CHECK(rating >= 1 AND rating <= 5),
        taste_notes TEXT,
        effect_notes TEXT,
        created_at TEXT DEFAULT (datetime('now')),
        updated_at TEXT DEFAULT (datetime('now')),
        FOREIGN KEY (plant_id) REFERENCES plants(id) ON DELETE RESTRICT
      )
    ''');

    // ‚úÖ CRITICAL FIX: Explicitly list v13 columns to prevent data loss
    // v13 harvests has: id, plant_id, harvest_date, wet_weight, dry_weight, created_at
    // v14 adds 11 new columns which will get NULL/default values
    //
    // ‚ö†Ô∏è SCHEMA MISMATCH NOTE (BUG #6.1):
    // After migration, harvests will have NULL values for new v14 fields:
    // - drying_start_date, drying_end_date, drying_days, drying_method,
    //   drying_temperature, drying_humidity
    // - curing_start_date, curing_end_date, curing_days, curing_method, curing_notes
    // - thc_percentage, cbd_percentage, terpene_profile
    // - rating, taste_notes, effect_notes, overall_notes, updated_at
    //
    // This is EXPECTED BEHAVIOR and does NOT cause data loss.
    // Users can fill in these values after migration via the UI.
    await db.execute('''
      INSERT INTO harvests_new (id, plant_id, harvest_date, wet_weight, dry_weight, created_at)
      SELECT id, plant_id, harvest_date, wet_weight, dry_weight, created_at
      FROM harvests
    ''');
    await db.execute('DROP TABLE harvests');
    await db.execute('ALTER TABLE harvests_new RENAME TO harvests');

    AppLogger.info(
      'Migration_v14',
      '  ‚úÖ harvests: ON DELETE CASCADE ‚Üí RESTRICT',
    );

    // ===========================================
    // STEP 5: Rebuild rdwc_logs with RESTRICT
    // ===========================================
    AppLogger.info(
      'Migration_v14',
      'üìù Step 5/9: Rebuilding rdwc_logs (CASCADE ‚Üí RESTRICT)',
    );

    await db.execute('''
      CREATE TABLE rdwc_logs_new (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        system_id INTEGER NOT NULL,
        log_date TEXT DEFAULT (datetime('now')),
        log_type TEXT NOT NULL CHECK(log_type IN ('ADDBACK', 'FULLCHANGE', 'MAINTENANCE', 'MEASUREMENT')),
        level_before REAL,
        water_added REAL,
        level_after REAL,
        water_consumed REAL,
        ph_before REAL,
        ph_after REAL,
        ec_before REAL,
        ec_after REAL,
        note TEXT,
        logged_by TEXT,
        archived INTEGER DEFAULT 0,
        created_at TEXT DEFAULT (datetime('now')),
        FOREIGN KEY (system_id) REFERENCES rdwc_systems(id) ON DELETE RESTRICT
      )
    ''');

    // ‚úÖ FIX: Transform log_type to uppercase to match CHECK constraint
    await db.execute('''
      INSERT INTO rdwc_logs_new
      SELECT id, system_id, log_date,
             UPPER(log_type) as log_type,  -- Transform to uppercase
             level_before, water_added, level_after,
             water_consumed, ph_before, ph_after, ec_before, ec_after, note, logged_by,
             archived, created_at
      FROM rdwc_logs
    ''');

    await db.execute('DROP TABLE rdwc_logs');
    await db.execute('ALTER TABLE rdwc_logs_new RENAME TO rdwc_logs');

    AppLogger.info(
      'Migration_v14',
      '  ‚úÖ rdwc_logs: ON DELETE CASCADE ‚Üí RESTRICT',
    );

    // ===========================================
    // STEP 6: Rebuild rdwc_log_fertilizers with RESTRICT
    // ===========================================
    AppLogger.info(
      'Migration_v14',
      'üìù Step 6/9: Rebuilding rdwc_log_fertilizers',
    );

    // ‚úÖ CRITICAL FIX: rdwc_log_fertilizers constraints corrected
    // - rdwc_log_id: RESTRICT ‚Üí CASCADE (child data should be deleted with parent log)
    // - amount_type: CHECK constraint must match v8 schema ('PER_LITER', 'TOTAL')
    await db.execute('''
      CREATE TABLE rdwc_log_fertilizers_new (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        rdwc_log_id INTEGER NOT NULL,
        fertilizer_id INTEGER NOT NULL,
        amount REAL NOT NULL,
        amount_type TEXT NOT NULL CHECK(amount_type IN ('PER_LITER', 'TOTAL')),
        created_at TEXT DEFAULT (datetime('now')),
        FOREIGN KEY (rdwc_log_id) REFERENCES rdwc_logs(id) ON DELETE CASCADE,
        FOREIGN KEY (fertilizer_id) REFERENCES fertilizers(id) ON DELETE RESTRICT
      )
    ''');

    await db.execute('''
      INSERT INTO rdwc_log_fertilizers_new (id, rdwc_log_id, fertilizer_id, amount, amount_type, created_at)
      SELECT id, rdwc_log_id, fertilizer_id, amount, amount_type,
             datetime('now') as created_at
      FROM rdwc_log_fertilizers
    ''');
    await db.execute('DROP TABLE rdwc_log_fertilizers');
    await db.execute(
      'ALTER TABLE rdwc_log_fertilizers_new RENAME TO rdwc_log_fertilizers',
    );

    AppLogger.info(
      'Migration_v14',
      '  ‚úÖ rdwc_log_fertilizers: Schema fixed (CASCADE for rdwc_log_id, RESTRICT for fertilizer_id)',
    );

    // ===========================================
    // STEP 7: Rebuild hardware with RESTRICT
    // ===========================================
    AppLogger.info(
      'Migration_v14',
      'üìù Step 7/9: Rebuilding hardware (CASCADE ‚Üí RESTRICT)',
    );

    await db.execute('''
      CREATE TABLE hardware_new (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        room_id INTEGER NOT NULL,
        name TEXT NOT NULL,
        type TEXT NOT NULL,
        brand TEXT,
        model TEXT,
        wattage REAL,
        purchase_date TEXT,
        active INTEGER DEFAULT 1,
        notes TEXT,
        created_at TEXT DEFAULT (datetime('now')),
        FOREIGN KEY (room_id) REFERENCES rooms(id) ON DELETE RESTRICT
      )
    ''');

    await db.execute('INSERT INTO hardware_new SELECT * FROM hardware');
    await db.execute('DROP TABLE hardware');
    await db.execute('ALTER TABLE hardware_new RENAME TO hardware');

    AppLogger.info(
      'Migration_v14',
      '  ‚úÖ hardware: ON DELETE CASCADE ‚Üí RESTRICT',
    );

    // ===========================================
    // STEP 8: Create indexes for archived filtering
    // ===========================================
    AppLogger.info('Migration_v14', 'üìù Step 8/9: Creating archived indexes');

    await db.execute(
      'CREATE INDEX idx_plant_logs_plant_archived ON plant_logs(plant_id, archived)',
    );
    await db.execute(
      'CREATE INDEX idx_plant_logs_archived_date ON plant_logs(archived, log_date DESC)',
    );
    await db.execute(
      'CREATE INDEX idx_rdwc_logs_system_archived ON rdwc_logs(system_id, archived)',
    );
    await db.execute(
      'CREATE INDEX idx_rdwc_logs_archived_date ON rdwc_logs(archived, log_date DESC)',
    );
    await db.execute('CREATE INDEX idx_rooms_archived ON rooms(archived)');

    AppLogger.info('Migration_v14', '  ‚úÖ 5 archived indexes created');

    // ===========================================
    // STEP 9: Re-create essential indexes
    // ===========================================
    AppLogger.info(
      'Migration_v14',
      'üìù Step 9/9: Re-creating essential indexes',
    );

    // plant_logs
    await db.execute('CREATE INDEX idx_logs_plant ON plant_logs(plant_id)');
    await db.execute('CREATE INDEX idx_logs_date ON plant_logs(log_date DESC)');

    // photos
    await db.execute('CREATE INDEX idx_photos_log ON photos(log_id)');

    // harvests
    await db.execute('CREATE INDEX idx_harvests_plant ON harvests(plant_id)');
    await db.execute(
      'CREATE INDEX idx_harvests_date ON harvests(harvest_date DESC)',
    );
    await db.execute(
      'CREATE INDEX idx_harvests_plant_date ON harvests(plant_id, harvest_date DESC)',
    );

    // rdwc_logs
    await db.execute(
      'CREATE INDEX idx_rdwc_logs_system_date ON rdwc_logs(system_id, log_date DESC)',
    );
    await db.execute(
      'CREATE INDEX idx_rdwc_logs_system_type_date ON rdwc_logs(system_id, log_type, log_date DESC)',
    );

    // hardware
    await db.execute('CREATE INDEX idx_hardware_room ON hardware(room_id)');
    await db.execute(
      'CREATE INDEX idx_hardware_room_active ON hardware(room_id, active)',
    );
    await db.execute(
      'CREATE UNIQUE INDEX idx_hardware_room_name_type_unique ON hardware(room_id, name, type)',
    );

    AppLogger.info('Migration_v14', '  ‚úÖ 11 essential indexes re-created');

    // ===========================================
    // COMPLETION
    // ===========================================
    AppLogger.info('Migration_v14', 'üéâ SOFT-DELETE SYSTEM COMPLETE!');
    AppLogger.info('Migration_v14', 'Data protection:');
    AppLogger.info('Migration_v14', '  ‚úÖ CASCADE DELETE ‚Üí RESTRICT (7 tables)');
    AppLogger.info('Migration_v14', '  ‚úÖ archived flags added (3 tables)');
    AppLogger.info('Migration_v14', '  ‚úÖ 16 indexes created');
    AppLogger.info('Migration_v14', '  üîí Data loss prevented on deletion');
  },
  down: (db) async {
    // Rollback is complex due to SQLite limitations
    // Would need to rebuild tables again with CASCADE DELETE
    AppLogger.warning(
      'Migration_v14',
      '‚ö†Ô∏è Rollback not implemented (archived columns remain)',
    );
  },
);
